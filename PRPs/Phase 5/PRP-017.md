# PRP-017: Bulk Operations

## Goal
Build a high-performance bulk operations system that enables businesses to process large-scale data changes (1M+ records) with real-time progress tracking, error handling, and rollback capabilities.

## Why This Matters
- **Scale**: Distributors need to update thousands of products/inventory items at once
- **Efficiency**: Manual updates are time-consuming and error-prone
- **Recovery**: Failed bulk operations need reliable rollback mechanisms
- **Performance**: Large operations shouldn't block the UI or timeout

## What We're Building
A comprehensive bulk operations system featuring:
1. Streaming CSV processor for large files
2. Real-time progress tracking with SSE
3. Batch processing with configurable chunk sizes
4. Rollback system for failed operations
5. Operation history and audit trail

## Context & References
- **CSV Processing**: lib/csv/parser.ts - Existing secure CSV parser
- **Performance**: lib/realtime/performance-monitor.ts - Monitoring patterns
- **File Upload**: components/features/products/image-upload.tsx - Upload patterns
- **Inventory Types**: types/inventory.types.ts - Import/export schemas
- **Node.js Streams**: https://nodejs.org/api/stream.html
- **Papa Parse**: https://www.papaparse.com/docs
- **Server-Sent Events**: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events

## Implementation Blueprint

### Phase 1: Database Schema

```sql
-- Bulk operations tracking
CREATE TABLE bulk_operations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  organization_id UUID REFERENCES organizations(id) NOT NULL,
  operation_type TEXT NOT NULL CHECK (operation_type IN ('import', 'export', 'update', 'delete')),
  entity_type TEXT NOT NULL CHECK (entity_type IN ('products', 'inventory', 'pricing', 'customers')),
  status TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'cancelled', 'rolled_back')),
  
  -- File information
  file_name TEXT,
  file_size_bytes BIGINT,
  file_url TEXT,
  
  -- Progress tracking
  total_records INTEGER,
  processed_records INTEGER DEFAULT 0,
  successful_records INTEGER DEFAULT 0,
  failed_records INTEGER DEFAULT 0,
  
  -- Timing
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  estimated_completion TIMESTAMPTZ,
  
  -- Configuration
  config JSONB DEFAULT '{}',
  
  -- Results
  results JSONB DEFAULT '{}',
  error_log JSONB DEFAULT '[]',
  
  -- Audit
  created_at TIMESTAMPTZ DEFAULT NOW(),
  created_by UUID REFERENCES auth.users(id) NOT NULL,
  cancelled_at TIMESTAMPTZ,
  cancelled_by UUID REFERENCES auth.users(id)
);

-- Operation records for rollback
CREATE TABLE bulk_operation_records (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  operation_id UUID REFERENCES bulk_operations(id) ON DELETE CASCADE,
  record_index INTEGER NOT NULL,
  entity_id UUID,
  
  -- Change tracking
  action TEXT NOT NULL CHECK (action IN ('create', 'update', 'delete')),
  before_data JSONB,
  after_data JSONB,
  
  -- Status
  status TEXT NOT NULL DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed', 'rolled_back')),
  error TEXT,
  
  processed_at TIMESTAMPTZ,
  
  UNIQUE(operation_id, record_index)
);

-- Indexes
CREATE INDEX idx_bulk_operations_org_status ON bulk_operations(organization_id, status);
CREATE INDEX idx_bulk_operations_created ON bulk_operations(created_at DESC);
CREATE INDEX idx_bulk_operation_records_operation ON bulk_operation_records(operation_id, status);

-- RLS
ALTER TABLE bulk_operations ENABLE ROW LEVEL SECURITY;
ALTER TABLE bulk_operation_records ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own bulk operations" ON bulk_operations
  FOR SELECT USING (
    organization_id = (SELECT organization_id FROM user_profiles WHERE user_id = auth.uid())
  );

CREATE POLICY "Users can create bulk operations" ON bulk_operations
  FOR INSERT WITH CHECK (
    organization_id = (SELECT organization_id FROM user_profiles WHERE user_id = auth.uid())
  );

CREATE POLICY "Users can update own bulk operations" ON bulk_operations
  FOR UPDATE USING (
    organization_id = (SELECT organization_id FROM user_profiles WHERE user_id = auth.uid())
  );
```

### Phase 2: Bulk Operations Engine

```typescript
// lib/bulk/bulk-operations-engine.ts
import { EventEmitter } from 'events'
import { Readable, Transform, pipeline } from 'stream'
import { promisify } from 'util'
import Papa from 'papaparse'
import { createServerClient } from '@/lib/supabase/server'
import { z } from 'zod'
import type { Database } from '@/types/database.types'

const pipelineAsync = promisify(pipeline)

export interface BulkOperationConfig {
  operationType: 'import' | 'export' | 'update' | 'delete'
  entityType: 'products' | 'inventory' | 'pricing' | 'customers'
  chunkSize?: number
  maxConcurrent?: number
  validateOnly?: boolean
  rollbackOnError?: boolean
  mapping?: Record<string, string>
}

export interface BulkOperationProgress {
  operationId: string
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'cancelled' | 'rolled_back'
  totalRecords: number
  processedRecords: number
  successfulRecords: number
  failedRecords: number
  estimatedTimeRemaining?: number
  currentChunk?: number
  totalChunks?: number
}

export class BulkOperationsEngine extends EventEmitter {
  private supabase: ReturnType<typeof createServerClient>
  private activeOperations = new Map<string, AbortController>()

  constructor() {
    super()
    this.supabase = createServerClient()
  }

  async startOperation(
    file: File | Readable,
    config: BulkOperationConfig,
    userId: string
  ): Promise<string> {
    // Create operation record
    const { data: operation, error } = await this.supabase
      .from('bulk_operations')
      .insert({
        operation_type: config.operationType,
        entity_type: config.entityType,
        file_name: file instanceof File ? file.name : 'stream',
        file_size_bytes: file instanceof File ? file.size : null,
        status: 'pending',
        config,
        created_by: userId
      })
      .select()
      .single()

    if (error) throw error

    // Create abort controller
    const abortController = new AbortController()
    this.activeOperations.set(operation.id, abortController)

    // Start processing in background
    this.processOperation(operation.id, file, config, abortController.signal)
      .catch(err => {
        console.error(`Bulk operation ${operation.id} failed:`, err)
        this.updateOperationStatus(operation.id, 'failed', { error: err.message })
      })

    return operation.id
  }

  private async processOperation(
    operationId: string,
    file: File | Readable,
    config: BulkOperationConfig,
    signal: AbortSignal
  ): Promise<void> {
    try {
      // Update status to processing
      await this.updateOperationStatus(operationId, 'processing')

      // Get the appropriate processor
      const processor = this.getProcessor(config.entityType)

      // Create streams - only consume once
      const inputStream = typeof File !== 'undefined' && file instanceof File 
        ? Readable.fromWeb ? Readable.fromWeb(file.stream()) : require('stream').Readable.fromWeb(file.stream())
        : file

      const parseStream = this.createParseStream(config)
      const validateStream = this.createValidateStream(processor.schema)
      const processStream = this.createProcessStream(
        operationId,
        processor,
        config,
        signal
      )

      // Run pipeline
      await pipelineAsync(
        inputStream,
        parseStream,
        validateStream,
        processStream
      )

      // Check if cancelled
      if (signal.aborted) {
        await this.updateOperationStatus(operationId, 'cancelled')
        return
      }

      // Mark as completed
      await this.updateOperationStatus(operationId, 'completed')

    } finally {
      this.activeOperations.delete(operationId)
    }
  }

  private async countTotalRecords(
    inputStream: Readable,
    config: BulkOperationConfig
  ): Promise<number> {
    return new Promise((resolve, reject) => {
      let totalRecords = 0
      let isFirstLine = true

      const countStream = new Transform({
        objectMode: true,
        transform(chunk: any, encoding: string, callback: Function) {
          const csvData = chunk.toString()
          const lines = csvData.split(/\r?\n/)
          
          for (const line of lines) {
            if (!line.trim()) continue
            
            if (isFirstLine) {
              // Skip header row
              isFirstLine = false
              continue
            }
            
            // Simple validation to ensure it's a data row
            if (line.includes(',') || line.includes('"')) {
              totalRecords++
            }
          }
          
          callback()
        }
      })

      countStream.on('end', () => resolve(totalRecords))
      countStream.on('error', reject)
      
      inputStream.pipe(countStream)
    })
  }

  private createParseStream(config: BulkOperationConfig): Transform {
    let buffer = ''
    let headers: string[] | null = null
    let rowIndex = 0

    return new Transform({
      objectMode: true,
      transform(chunk: any, encoding: string, callback: Function) {
        buffer += chunk.toString()
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          if (!headers) {
            headers = Papa.parse(line).data[0] as string[]
            continue
          }

          const row = Papa.parse(line).data[0]
          if (row && row.length > 0) {
            const data: Record<string, any> = {}
            headers.forEach((header, index) => {
              const mappedHeader = config.mapping?.[header] || header
              data[mappedHeader] = row[index]
            })
            
            this.push({ index: rowIndex++, data })
          }
        }

        callback()
      },
      flush(callback: Function) {
        if (buffer && headers) {
          const row = Papa.parse(buffer).data[0]
          if (row && row.length > 0) {
            const data: Record<string, any> = {}
            headers.forEach((header, index) => {
              const mappedHeader = config.mapping?.[header] || header
              data[mappedHeader] = row[index]
            })
            
            this.push({ index: rowIndex++, data })
          }
        }
        callback()
      }
    })
  }

  private createValidateStream(schema: z.ZodSchema): Transform {
    return new Transform({
      objectMode: true,
      transform(record: { index: number; data: any }, encoding: string, callback: Function) {
        try {
          const validated = schema.parse(record.data)
          this.push({ ...record, data: validated, valid: true })
        } catch (error) {
          if (error instanceof z.ZodError) {
            this.push({
              ...record,
              valid: false,
              errors: error.errors.map(e => ({
                path: e.path.join('.'),
                message: e.message
              }))
            })
          } else {
            this.push({
              ...record,
              valid: false,
              errors: [{ message: 'Unknown validation error' }]
            })
          }
        }
        callback()
      }
    })
  }

  private createProcessStream(
    operationId: string,
    processor: EntityProcessor,
    config: BulkOperationConfig,
    signal: AbortSignal
  ): Transform {
    const chunkSize = config.chunkSize || 100
    let chunk: any[] = []
    let totalProcessed = 0
    let totalSuccess = 0
    let totalFailed = 0
    let totalRecords = 0 // Count records dynamically
    const startTime = Date.now()

    const processChunk = async () => {
      if (chunk.length === 0) return

      const chunkToProcess = [...chunk]
      chunk = []

      // Check if cancelled
      if (signal.aborted) return

      // Process records
      const results = await Promise.allSettled(
        chunkToProcess.map(record => 
          processor.process(record, config, this.supabase)
        )
      )

      // Record results
      const recordsToInsert = chunkToProcess.map((record, index) => {
        const result = results[index]
        const success = result.status === 'fulfilled'
        
        return {
          operation_id: operationId,
          record_index: record.index,
          entity_id: success ? result.value?.id : null,
          action: config.operationType === 'import' ? 'create' : config.operationType,
          before_data: record.before,
          after_data: success ? result.value : record.data,
          status: success ? 'completed' : 'failed',
          error: result.status === 'rejected' ? result.reason?.message : null
        }
      })

      await this.supabase.from('bulk_operation_records').insert(recordsToInsert)

      // Update progress
      totalProcessed += chunkToProcess.length
      totalSuccess += results.filter(r => r.status === 'fulfilled').length
      totalFailed += results.filter(r => r.status === 'rejected').length

      const progress: BulkOperationProgress = {
        operationId,
        status: 'processing',
        totalRecords,
        processedRecords: totalProcessed,
        successfulRecords: totalSuccess,
        failedRecords: totalFailed,
        estimatedTimeRemaining: this.estimateTimeRemaining(
          totalProcessed,
          totalRecords,
          startTime
        )
      }

      // Emit progress
      this.emit('progress', progress)

      // Update database
      await this.supabase
        .from('bulk_operations')
        .update({
          processed_records: totalProcessed,
          successful_records: totalSuccess,
          failed_records: totalFailed,
          estimated_completion: new Date(
            Date.now() + (progress.estimatedTimeRemaining || 0) * 1000
          ).toISOString()
        })
        .eq('id', operationId)

      // Check if should rollback
      if (config.rollbackOnError && totalFailed > 0) {
        throw new Error('Operation failed, initiating rollback')
      }
    }

    return new Transform({
      objectMode: true,
      async transform(record: any, encoding: string, callback: Function) {
        // Count all records (valid and invalid)
        totalRecords++
        
        if (!record.valid && !config.validateOnly) {
          totalFailed++
          await this.supabase.from('bulk_operation_records').insert({
            operation_id: operationId,
            record_index: record.index,
            action: config.operationType === 'import' ? 'create' : config.operationType,
            status: 'failed',
            error: JSON.stringify(record.errors)
          })
          
          // Update total records count in database
          await this.supabase
            .from('bulk_operations')
            .update({ total_records: totalRecords })
            .eq('id', operationId)
            
        } else if (!config.validateOnly) {
          chunk.push(record)
          
          if (chunk.length >= chunkSize) {
            try {
              await processChunk()
            } catch (error) {
              return callback(error)
            }
          }
        }
        
        callback()
      },
      async flush(callback: Function) {
        try {
          await processChunk()
          
          // Final update of total records
          await this.supabase
            .from('bulk_operations')
            .update({ total_records: totalRecords })
            .eq('id', operationId)
            
          callback()
        } catch (error) {
          callback(error)
        }
      }
    })
  }

  async cancelOperation(operationId: string, userId: string): Promise<void> {
    // Cancel the operation
    const controller = this.activeOperations.get(operationId)
    if (controller) {
      controller.abort()
    }

    // Update status
    await this.supabase
      .from('bulk_operations')
      .update({
        status: 'cancelled',
        cancelled_at: new Date().toISOString(),
        cancelled_by: userId
      })
      .eq('id', operationId)
  }

  async rollbackOperation(operationId: string): Promise<void> {
    // Update operation status to processing rollback
    await this.updateOperationStatus(operationId, 'processing', {
      results: { rollback_started: new Date().toISOString() }
    })

    try {
      // Get total count of records to rollback
      const { count: totalRecords } = await this.supabase
        .from('bulk_operation_records')
        .select('*', { count: 'exact', head: true })
        .eq('operation_id', operationId)
        .eq('status', 'completed')

      if (!totalRecords || totalRecords === 0) {
        await this.updateOperationStatus(operationId, 'rolled_back')
        return
      }

      // Process rollbacks in batches
      const batchSize = 1000
      const maxConcurrent = 5
      let processedCount = 0
      let successCount = 0
      let failedCount = 0
      const startTime = Date.now()

      // Get processor once
      const processor = this.getProcessor(
        await this.getOperationEntityType(operationId)
      )

      // Use cursor-style processing to avoid offset issues
      while (true) {
        // Always get the first batch of 'completed' records
        const { data: records, error } = await this.supabase
          .from('bulk_operation_records')
          .select('*')
          .eq('operation_id', operationId)
          .eq('status', 'completed')
          .order('record_index', { ascending: false })
          .limit(batchSize)

        if (error) throw error
        if (!records?.length) break // No more records to process

        // Process batch with concurrency control
        const results = await this.processRollbackBatch(
          records,
          processor,
          maxConcurrent
        )

        // Update record statuses in batch
        const recordUpdates = records.map((record, index) => ({
          id: record.id,
          status: results[index].success ? 'rolled_back' : 'failed',
          error: results[index].success ? null : results[index].error
        }))

        // Update in chunks to avoid large transactions
        const updateChunkSize = 100
        for (let i = 0; i < recordUpdates.length; i += updateChunkSize) {
          const chunk = recordUpdates.slice(i, i + updateChunkSize)
          await Promise.all(
            chunk.map(update =>
              this.supabase
                .from('bulk_operation_records')
                .update({
                  status: update.status,
                  error: update.error
                })
                .eq('id', update.id)
            )
          )
        }

        // Update progress counters
        processedCount += records.length
        successCount += results.filter(r => r.success).length
        failedCount += results.filter(r => !r.success).length

        // Emit progress
        const progress = {
          operationId,
          type: 'rollback',
          status: 'processing',
          totalRecords,
          processedRecords: processedCount,
          successfulRecords: successCount,
          failedRecords: failedCount,
          estimatedTimeRemaining: this.estimateTimeRemaining(
            processedCount,
            totalRecords,
            startTime
          )
        }

        this.emit('rollback-progress', progress)

        // Update operation progress in database
        await this.supabase
          .from('bulk_operations')
          .update({
            results: {
              rollback_progress: {
                total: totalRecords,
                processed: processedCount,
                successful: successCount,
                failed: failedCount,
                percentage: Math.round((processedCount / totalRecords) * 100)
              }
            }
          })
          .eq('id', operationId)
      }

      // Final status update
      await this.updateOperationStatus(operationId, 'rolled_back', {
        results: {
          rollback_completed: new Date().toISOString(),
          rollback_summary: {
            total: totalRecords,
            successful: successCount,
            failed: failedCount
          }
        }
      })

    } catch (error) {
      console.error(`Rollback operation ${operationId} failed:`, error)
      await this.updateOperationStatus(operationId, 'failed', {
        error_log: [{ 
          message: error instanceof Error ? error.message : 'Unknown rollback error',
          timestamp: new Date().toISOString()
        }]
      })
      throw error
    }
  }

  private async processRollbackBatch(
    records: any[],
    processor: EntityProcessor,
    maxConcurrent: number
  ): Promise<Array<{ success: boolean; error?: string }>> {
    const results: Array<{ success: boolean; error?: string }> = []
    const processing = new Set<Promise<void>>()

    for (let i = 0; i < records.length; i++) {
      const record = records[i]

      // Wait if too many concurrent operations
      while (processing.size >= maxConcurrent) {
        await Promise.race(processing)
      }

      // Process rollback
      const promise = processor.rollback(record, this.supabase)
        .then(() => {
          results[i] = { success: true }
        })
        .catch((error) => {
          console.error(`Failed to rollback record ${record.id}:`, error)
          results[i] = { 
            success: false, 
            error: error instanceof Error ? error.message : 'Unknown error'
          }
        })
        .finally(() => {
          processing.delete(promise)
        })

      processing.add(promise)
    }

    // Wait for all processing to complete
    await Promise.all(processing)
    return results
  }

  private async updateOperationStatus(
    operationId: string,
    status: Database['public']['Tables']['bulk_operations']['Row']['status'],
    additionalData?: Record<string, any>
  ): Promise<void> {
    const updateData: any = { status }
    
    if (status === 'processing') {
      updateData.started_at = new Date().toISOString()
    } else if (status === 'completed' || status === 'failed' || status === 'rolled_back') {
      updateData.completed_at = new Date().toISOString()
    }

    if (additionalData) {
      Object.assign(updateData, additionalData)
    }

    await this.supabase
      .from('bulk_operations')
      .update(updateData)
      .eq('id', operationId)
  }

  private estimateTimeRemaining(
    processed: number,
    total: number,
    startTime: number
  ): number {
    if (processed === 0) return 0
    
    const elapsed = Date.now() - startTime
    const rate = processed / (elapsed / 1000)
    const remaining = total - processed
    
    return Math.ceil(remaining / rate)
  }

  private getProcessor(entityType: string): EntityProcessor {
    switch (entityType) {
      case 'inventory':
        return new InventoryProcessor()
      case 'products':
        return new ProductProcessor()
      case 'pricing':
        return new PricingProcessor()
      case 'customers':
        return new CustomerProcessor()
      default:
        throw new Error(`Unknown entity type: ${entityType}`)
    }
  }

  private async getOperationEntityType(operationId: string): Promise<string> {
    const { data, error } = await this.supabase
      .from('bulk_operations')
      .select('entity_type')
      .eq('id', operationId)
      .single()

    if (error) throw error
    return data.entity_type
  }
}

// Entity processors
abstract class EntityProcessor {
  abstract schema: z.ZodSchema
  abstract async process(
    record: any,
    config: BulkOperationConfig,
    supabase: ReturnType<typeof createServerClient>
  ): Promise<any>
  abstract async rollback(
    record: any,
    supabase: ReturnType<typeof createServerClient>
  ): Promise<void>
}

class InventoryProcessor extends EntityProcessor {
  schema = z.object({
    sku: z.string().min(1),
    warehouse_code: z.string().min(1),
    quantity: z.number().int().min(0),
    reason: z.string().optional(),
    notes: z.string().optional()
  })

  async process(record: any, config: BulkOperationConfig, supabase: any) {
    // Implementation for inventory processing
    const { sku, warehouse_code, quantity, reason, notes } = record.data

    // Look up product and warehouse
    const [productResult, warehouseResult] = await Promise.all([
      supabase.from('products').select('id').eq('sku', sku).single(),
      supabase.from('warehouses').select('id').eq('code', warehouse_code).single()
    ])

    if (productResult.error || warehouseResult.error) {
      throw new Error('Product or warehouse not found')
    }

    // Update inventory
    const { data, error } = await supabase
      .from('inventory')
      .update({ 
        quantity,
        last_bulk_update: new Date().toISOString()
      })
      .eq('product_id', productResult.data.id)
      .eq('warehouse_id', warehouseResult.data.id)
      .select()
      .single()

    if (error) throw error
    return data
  }

  async rollback(record: any, supabase: any) {
    if (record.before_data) {
      await supabase
        .from('inventory')
        .update(record.before_data)
        .eq('id', record.entity_id)
    }
  }
}

class ProductProcessor extends EntityProcessor {
  schema = z.object({
    sku: z.string().min(1),
    name: z.string().min(1),
    description: z.string().optional(),
    category: z.string().optional(),
    price: z.number().positive().optional()
  })

  async process(record: any, config: BulkOperationConfig, supabase: any) {
    const { sku, name, description, category, price } = record.data

    if (config.operationType === 'import') {
      const { data, error } = await supabase
        .from('products')
        .upsert({
          sku,
          name,
          description,
          category,
          price
        })
        .select()
        .single()

      if (error) throw error
      return data
    } else if (config.operationType === 'update') {
      const { data, error } = await supabase
        .from('products')
        .update({ name, description, category, price })
        .eq('sku', sku)
        .select()
        .single()

      if (error) throw error
      return data
    }
  }

  async rollback(record: any, supabase: any) {
    if (record.action === 'create') {
      await supabase.from('products').delete().eq('id', record.entity_id)
    } else if (record.action === 'update' && record.before_data) {
      await supabase
        .from('products')
        .update(record.before_data)
        .eq('id', record.entity_id)
    }
  }
}

class PricingProcessor extends EntityProcessor {
  schema = z.object({
    sku: z.string().min(1),
    price_tier: z.string().min(1),
    price: z.number().positive(),
    min_quantity: z.number().int().min(1).optional()
  })

  async process(record: any, config: BulkOperationConfig, supabase: any) {
    // Implementation for pricing processing
    const { sku, price_tier, price, min_quantity } = record.data

    // Look up product
    const { data: product, error: productError } = await supabase
      .from('products')
      .select('id')
      .eq('sku', sku)
      .single()

    if (productError) throw new Error('Product not found')

    const { data, error } = await supabase
      .from('product_pricing')
      .upsert({
        product_id: product.id,
        price_tier,
        price,
        min_quantity: min_quantity || 1
      })
      .select()
      .single()

    if (error) throw error
    return data
  }

  async rollback(record: any, supabase: any) {
    if (record.action === 'create') {
      await supabase.from('product_pricing').delete().eq('id', record.entity_id)
    } else if (record.before_data) {
      await supabase
        .from('product_pricing')
        .update(record.before_data)
        .eq('id', record.entity_id)
    }
  }
}

class CustomerProcessor extends EntityProcessor {
  schema = z.object({
    email: z.string().email(),
    name: z.string().min(1),
    company: z.string().optional(),
    price_tier: z.string().optional()
  })

  async process(record: any, config: BulkOperationConfig, supabase: any) {
    const { email, name, company, price_tier } = record.data

    const { data, error } = await supabase
      .from('customers')
      .upsert({
        email,
        name,
        company,
        price_tier: price_tier || 'standard'
      })
      .select()
      .single()

    if (error) throw error
    return data
  }

  async rollback(record: any, supabase: any) {
    if (record.action === 'create') {
      await supabase.from('customers').delete().eq('id', record.entity_id)
    } else if (record.before_data) {
      await supabase
        .from('customers')
        .update(record.before_data)
        .eq('id', record.entity_id)
    }
  }
}
```

### Phase 3: Stream Processor

```typescript
// lib/bulk/stream-processor.ts
import { Transform, Writable } from 'stream'
import { pipeline } from 'stream/promises'
import Papa from 'papaparse'

export class CSVStreamProcessor {
  private chunkSize: number
  private concurrency: number

  constructor(options: { chunkSize?: number; concurrency?: number } = {}) {
    this.chunkSize = options.chunkSize || 1000
    this.concurrency = options.concurrency || 5
  }

  createParseStream(): Transform {
    let buffer = ''
    let headers: string[] | null = null
    let rowCount = 0

    return new Transform({
      objectMode: true,
      transform(chunk: Buffer, encoding: string, callback: Function) {
        buffer += chunk.toString()
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          if (!line.trim()) continue

          const parsed = Papa.parse(line, {
            header: !headers,
            skipEmptyLines: true
          })

          if (!headers && parsed.meta.fields) {
            headers = parsed.meta.fields
            this.emit('headers', headers)
            continue
          }

          if (parsed.data.length > 0) {
            const row = headers ? 
              Object.fromEntries(
                headers.map((h, i) => [h, parsed.data[0][i]])
              ) : parsed.data[0]
            
            this.push({
              index: rowCount++,
              data: row,
              raw: line
            })
          }
        }

        callback()
      },
      flush(callback: Function) {
        if (buffer.trim() && headers) {
          const parsed = Papa.parse(buffer, { skipEmptyLines: true })
          if (parsed.data.length > 0) {
            const row = Object.fromEntries(
              headers.map((h, i) => [h, parsed.data[0][i]])
            )
            this.push({
              index: rowCount++,
              data: row,
              raw: buffer
            })
          }
        }
        callback()
      }
    })
  }

  createBatchStream(): Transform {
    let batch: any[] = []

    return new Transform({
      objectMode: true,
      transform(record: any, encoding: string, callback: Function) {
        batch.push(record)
        
        if (batch.length >= this.chunkSize) {
          this.push([...batch])
          batch = []
        }
        
        callback()
      },
      flush(callback: Function) {
        if (batch.length > 0) {
          this.push(batch)
        }
        callback()
      }
    }.bind(this))
  }

  createConcurrentProcessor<T>(
    processFunc: (batch: any[]) => Promise<T[]>
  ): Transform {
    const processing = new Set<Promise<void>>()

    return new Transform({
      objectMode: true,
      async transform(batch: any[], encoding: string, callback: Function) {
        // Wait if too many concurrent operations
        while (processing.size >= this.concurrency) {
          await Promise.race(processing)
        }

        // Process batch
        const promise = processFunc(batch)
          .then(results => {
            this.push({ batch, results })
          })
          .catch(error => {
            this.push({ batch, error })
          })
          .finally(() => {
            processing.delete(promise)
          })

        processing.add(promise)
        callback()
      },
      async flush(callback: Function) {
        // Wait for all processing to complete
        await Promise.all(processing)
        callback()
      }
    }.bind(this))
  }

  createProgressStream(
    onProgress: (progress: {
      processed: number
      total?: number
      rate: number
    }) => void
  ): Transform {
    let processed = 0
    let startTime = Date.now()
    let lastEmit = 0

    return new Transform({
      objectMode: true,
      transform(chunk: any, encoding: string, callback: Function) {
        processed++
        
        const now = Date.now()
        if (now - lastEmit > 100) { // Emit every 100ms
          const elapsed = (now - startTime) / 1000
          const rate = processed / elapsed
          
          onProgress({ processed, rate })
          lastEmit = now
        }
        
        this.push(chunk)
        callback()
      }
    })
  }
}

// Usage example
export async function processLargeCSV(
  fileStream: NodeJS.ReadableStream,
  processor: (batch: any[]) => Promise<any[]>,
  onProgress: (progress: any) => void
): Promise<{ total: number; successful: number; failed: number }> {
  const streamProcessor = new CSVStreamProcessor({
    chunkSize: 500,
    concurrency: 3
  })

  let stats = { total: 0, successful: 0, failed: 0 }

  await pipeline(
    fileStream,
    streamProcessor.createParseStream(),
    streamProcessor.createProgressStream(onProgress),
    streamProcessor.createBatchStream(),
    streamProcessor.createConcurrentProcessor(processor),
    new Writable({
      objectMode: true,
      write(result: any, encoding: string, callback: Function) {
        stats.total += result.batch.length
        
        if (result.error) {
          stats.failed += result.batch.length
        } else {
          stats.successful += result.results.filter(r => r.success).length
          stats.failed += result.results.filter(r => !r.success).length
        }
        
        callback()
      }
    })
  )

  return stats
}
```

### Phase 4: Progress Tracking (SSE)

```typescript
// app/api/bulk/progress/[operationId]/route.ts
import { createServerClient } from '@/lib/supabase/server'
import { BulkOperationsEngine } from '@/lib/bulk/bulk-operations-engine'

export async function GET(
  request: Request,
  { params }: { params: { operationId: string } }
) {
  const supabase = createServerClient()
  
  // Verify user has access
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) {
    return new Response('Unauthorized', { status: 401 })
  }

  // Verify operation belongs to user's org
  const { data: operation } = await supabase
    .from('bulk_operations')
    .select('*')
    .eq('id', params.operationId)
    .single()

  if (!operation) {
    return new Response('Not found', { status: 404 })
  }

  // Create SSE stream
  const encoder = new TextEncoder()
  const stream = new ReadableStream({
    async start(controller) {
      const engine = new BulkOperationsEngine()
      
      // Send initial state
      controller.enqueue(
        encoder.encode(`data: ${JSON.stringify({
          type: 'initial',
          progress: {
            operationId: operation.id,
            status: operation.status,
            totalRecords: operation.total_records || 0,
            processedRecords: operation.processed_records || 0,
            successfulRecords: operation.successful_records || 0,
            failedRecords: operation.failed_records || 0,
            rollbackProgress: operation.results?.rollback_progress || null
          }
        })}\n\n`)
      )

      // Listen for progress updates
      const handleProgress = (progress: any) => {
        if (progress.operationId === params.operationId) {
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({
              type: 'progress',
              progress
            })}\n\n`)
          )
        }
      }

      // Listen for rollback progress updates
      const handleRollbackProgress = (progress: any) => {
        if (progress.operationId === params.operationId) {
          controller.enqueue(
            encoder.encode(`data: ${JSON.stringify({
              type: 'rollback-progress',
              progress
            })}\n\n`)
          )
        }
      }

      engine.on('progress', handleProgress)
      engine.on('rollback-progress', handleRollbackProgress)

      // Poll for updates if operation is running or being rolled back
      if (operation.status === 'processing' || 
          (operation.status === 'processing' && operation.results?.rollback_started)) {
        const pollInterval = setInterval(async () => {
          const { data: updated } = await supabase
            .from('bulk_operations')
            .select('*')
            .eq('id', params.operationId)
            .single()

          if (updated) {
            // Check if this is rollback progress
            const rollbackProgress = updated.results?.rollback_progress
            if (rollbackProgress) {
              handleRollbackProgress({
                operationId: updated.id,
                type: 'rollback',
                status: updated.status,
                totalRecords: rollbackProgress.total,
                processedRecords: rollbackProgress.processed,
                successfulRecords: rollbackProgress.successful,
                failedRecords: rollbackProgress.failed,
                percentage: rollbackProgress.percentage
              })
            } else {
              // Regular operation progress
              handleProgress({
                operationId: updated.id,
                status: updated.status,
                totalRecords: updated.total_records || 0,
                processedRecords: updated.processed_records || 0,
                successfulRecords: updated.successful_records || 0,
                failedRecords: updated.failed_records || 0
              })
            }

            // Close connection when operation is fully complete
            if (updated.status !== 'processing' && !rollbackProgress) {
              clearInterval(pollInterval)
              controller.close()
            }
          }
        }, 1000)

        // Cleanup on disconnect
        request.signal.addEventListener('abort', () => {
          clearInterval(pollInterval)
          engine.removeListener('progress', handleProgress)
          engine.removeListener('rollback-progress', handleRollbackProgress)
          controller.close()
        })
      } else {
        // For completed operations, close immediately after sending initial state
        setTimeout(() => controller.close(), 100)
      }
    }
  })

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive'
    }
  })
}
```

### Phase 5: Bulk Operations Dashboard

```tsx
// components/features/bulk/bulk-operations-dashboard.tsx
'use client'

import { useState, useEffect } from 'react'
import { useQuery, useMutation } from '@tanstack/react-query'
import { 
  Card, 
  CardContent, 
  CardDescription, 
  CardHeader, 
  CardTitle 
} from '@/components/ui/card'
import { Button } from '@/components/ui/button'
import { Progress } from '@/components/ui/progress'
import { Badge } from '@/components/ui/badge'
import { DataTable } from '@/components/ui/data-table'
import { 
  FileUp, 
  Download, 
  RefreshCw, 
  XCircle, 
  CheckCircle,
  AlertCircle,
  Clock,
  RotateCcw
} from 'lucide-react'
import { formatDistanceToNow } from 'date-fns'
import { toast } from 'sonner'
import { BulkUploadDialog } from './bulk-upload-dialog'
import { BulkProgressTracker } from './bulk-progress-tracker'
import { createBrowserClient } from '@/lib/supabase/client'

export function BulkOperationsDashboard() {
  const [selectedOperation, setSelectedOperation] = useState<string | null>(null)
  const [uploadDialogOpen, setUploadDialogOpen] = useState(false)
  const supabase = createBrowserClient()

  const { data: operations, refetch } = useQuery({
    queryKey: ['bulk-operations'],
    queryFn: async () => {
      const { data, error } = await supabase
        .from('bulk_operations')
        .select('*')
        .order('created_at', { ascending: false })
        .limit(50)

      if (error) throw error
      return data
    }
  })

  const cancelMutation = useMutation({
    mutationFn: async (operationId: string) => {
      const response = await fetch(`/api/bulk/cancel`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ operationId })
      })

      if (!response.ok) throw new Error('Failed to cancel operation')
    },
    onSuccess: () => {
      toast.success('Operation cancelled')
      refetch()
    }
  })

  const rollbackMutation = useMutation({
    mutationFn: async (operationId: string) => {
      const response = await fetch(`/api/bulk/rollback`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ operationId })
      })

      if (!response.ok) throw new Error('Failed to rollback operation')
    },
    onSuccess: () => {
      toast.success('Rollback initiated')
      refetch()
    }
  })

  const getStatusIcon = (status: string) => {
    switch (status) {
      case 'completed':
        return <CheckCircle className="h-4 w-4 text-green-500" />
      case 'failed':
        return <XCircle className="h-4 w-4 text-red-500" />
      case 'processing':
        return <RefreshCw className="h-4 w-4 animate-spin text-blue-500" />
      case 'cancelled':
        return <XCircle className="h-4 w-4 text-gray-500" />
      case 'rolled_back':
        return <RotateCcw className="h-4 w-4 text-orange-500" />
      default:
        return <Clock className="h-4 w-4 text-gray-400" />
    }
  }

  const columns = [
    {
      header: 'Status',
      cell: ({ row }: any) => (
        <div className="flex items-center gap-2">
          {getStatusIcon(row.original.status)}
          <Badge variant={
            row.original.status === 'completed' ? 'success' :
            row.original.status === 'failed' ? 'destructive' :
            row.original.status === 'processing' ? 'default' :
            'secondary'
          }>
            {row.original.status}
          </Badge>
        </div>
      )
    },
    {
      header: 'Type',
      cell: ({ row }: any) => (
        <div>
          <div className="font-medium capitalize">
            {row.original.operation_type} {row.original.entity_type}
          </div>
          <div className="text-xs text-muted-foreground">
            {row.original.file_name}
          </div>
        </div>
      )
    },
    {
      header: 'Progress',
      cell: ({ row }: any) => {
        const total = row.original.total_records || 0
        const processed = row.original.processed_records || 0
        const percentage = total > 0 ? (processed / total) * 100 : 0

        return (
          <div className="space-y-1">
            <Progress value={percentage} className="w-[100px]" />
            <div className="text-xs text-muted-foreground">
              {processed} / {total}
            </div>
          </div>
        )
      }
    },
    {
      header: 'Results',
      cell: ({ row }: any) => (
        <div className="text-sm">
          <div className="text-green-600">
             {row.original.successful_records || 0}
          </div>
          {(row.original.failed_records || 0) > 0 && (
            <div className="text-red-600">
               {row.original.failed_records}
            </div>
          )}
        </div>
      )
    },
    {
      header: 'Created',
      cell: ({ row }: any) => (
        <div className="text-sm text-muted-foreground">
          {formatDistanceToNow(new Date(row.original.created_at), { 
            addSuffix: true 
          })}
        </div>
      )
    },
    {
      header: 'Actions',
      cell: ({ row }: any) => (
        <div className="flex items-center gap-2">
          {row.original.status === 'processing' && (
            <Button
              size="sm"
              variant="outline"
              onClick={() => cancelMutation.mutate(row.original.id)}
            >
              Cancel
            </Button>
          )}
          {row.original.status === 'completed' && (
            <Button
              size="sm"
              variant="outline"
              onClick={() => rollbackMutation.mutate(row.original.id)}
            >
              Rollback
            </Button>
          )}
          {row.original.error_log?.length > 0 && (
            <Button
              size="sm"
              variant="ghost"
              onClick={() => {
                // Show error details
                toast.error(`${row.original.failed_records} errors found`, {
                  description: 'Download error log for details'
                })
              }}
            >
              <AlertCircle className="h-4 w-4" />
            </Button>
          )}
        </div>
      )
    }
  ]

  return (
    <div className="space-y-6">
      <div className="flex items-center justify-between">
        <div>
          <h2 className="text-2xl font-bold">Bulk Operations</h2>
          <p className="text-muted-foreground">
            Import, export, and update data in bulk
          </p>
        </div>
        <Button onClick={() => setUploadDialogOpen(true)}>
          <FileUp className="mr-2 h-4 w-4" />
          New Bulk Operation
        </Button>
      </div>

      {/* Active Operations */}
      {operations?.some(op => op.status === 'processing') && (
        <Card>
          <CardHeader>
            <CardTitle>Active Operations</CardTitle>
          </CardHeader>
          <CardContent className="space-y-4">
            {operations
              .filter(op => op.status === 'processing')
              .map(op => (
                <BulkProgressTracker
                  key={op.id}
                  operationId={op.id}
                  onComplete={() => refetch()}
                />
              ))}
          </CardContent>
        </Card>
      )}

      {/* Operations History */}
      <Card>
        <CardHeader>
          <CardTitle>Operation History</CardTitle>
          <CardDescription>
            Recent bulk operations and their status
          </CardDescription>
        </CardHeader>
        <CardContent>
          <DataTable
            columns={columns}
            data={operations || []}
          />
        </CardContent>
      </Card>

      {/* Upload Dialog */}
      <BulkUploadDialog
        open={uploadDialogOpen}
        onOpenChange={setUploadDialogOpen}
        onSuccess={() => {
          refetch()
          setUploadDialogOpen(false)
        }}
      />
    </div>
  )
}
```

### Phase 6: Bulk Upload Component

```tsx
// components/features/bulk/bulk-upload-dialog.tsx
'use client'

import { useState } from 'react'
import { useForm } from 'react-hook-form'
import { zodResolver } from '@hookform/resolvers/zod'
import { z } from 'zod'
import {
  Dialog,
  DialogContent,
  DialogDescription,
  DialogFooter,
  DialogHeader,
  DialogTitle,
} from '@/components/ui/dialog'
import {
  Form,
  FormControl,
  FormDescription,
  FormField,
  FormItem,
  FormLabel,
  FormMessage,
} from '@/components/ui/form'
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from '@/components/ui/select'
import { Button } from '@/components/ui/button'
import { Checkbox } from '@/components/ui/checkbox'
import { FileUpload } from '@/components/ui/file-upload'
import { Alert, AlertDescription } from '@/components/ui/alert'
import { Download, Info } from 'lucide-react'
import { toast } from 'sonner'

const formSchema = z.object({
  file: z.instanceof(File).refine(
    (file) => file.name.endsWith('.csv'),
    'File must be a CSV'
  ),
  operationType: z.enum(['import', 'update']),
  entityType: z.enum(['products', 'inventory', 'pricing', 'customers']),
  validateOnly: z.boolean().default(false),
  rollbackOnError: z.boolean().default(true),
})

interface BulkUploadDialogProps {
  open: boolean
  onOpenChange: (open: boolean) => void
  onSuccess: () => void
}

export function BulkUploadDialog({
  open,
  onOpenChange,
  onSuccess
}: BulkUploadDialogProps) {
  const [isUploading, setIsUploading] = useState(false)

  const form = useForm<z.infer<typeof formSchema>>({
    resolver: zodResolver(formSchema),
    defaultValues: {
      operationType: 'import',
      entityType: 'products',
      validateOnly: false,
      rollbackOnError: true,
    }
  })

  async function onSubmit(values: z.infer<typeof formSchema>) {
    setIsUploading(true)

    try {
      const formData = new FormData()
      formData.append('file', values.file)
      formData.append('operationType', values.operationType)
      formData.append('entityType', values.entityType)
      formData.append('validateOnly', values.validateOnly.toString())
      formData.append('rollbackOnError', values.rollbackOnError.toString())

      const response = await fetch('/api/bulk/upload', {
        method: 'POST',
        body: formData
      })

      if (!response.ok) {
        throw new Error('Upload failed')
      }

      const { operationId } = await response.json()
      
      toast.success('Bulk operation started', {
        description: `Operation ID: ${operationId}`
      })

      onSuccess()
    } catch (error) {
      toast.error('Failed to start bulk operation')
    } finally {
      setIsUploading(false)
    }
  }

  const downloadTemplate = () => {
    const entityType = form.watch('entityType')
    const templates: Record<string, string> = {
      products: 'sku,name,description,category,price\nPROD-001,Widget A,Description here,Hardware,29.99',
      inventory: 'sku,warehouse_code,quantity,reason,notes\nPROD-001,WH-001,100,cycle_count,Initial count',
      pricing: 'sku,price_tier,price,min_quantity\nPROD-001,wholesale,24.99,10',
      customers: 'email,name,company,price_tier\njohn@example.com,John Doe,Acme Corp,wholesale'
    }

    const blob = new Blob([templates[entityType]], { type: 'text/csv' })
    const url = URL.createObjectURL(blob)
    const a = document.createElement('a')
    a.href = url
    a.download = `${entityType}_template.csv`
    a.click()
    URL.revokeObjectURL(url)
  }

  return (
    <Dialog open={open} onOpenChange={onOpenChange}>
      <DialogContent className="sm:max-w-[600px]">
        <DialogHeader>
          <DialogTitle>Bulk Operation</DialogTitle>
          <DialogDescription>
            Upload a CSV file to perform bulk operations on your data
          </DialogDescription>
        </DialogHeader>

        <Form {...form}>
          <form onSubmit={form.handleSubmit(onSubmit)} className="space-y-4">
            <div className="grid grid-cols-2 gap-4">
              <FormField
                control={form.control}
                name="operationType"
                render={({ field }) => (
                  <FormItem>
                    <FormLabel>Operation Type</FormLabel>
                    <Select 
                      onValueChange={field.onChange} 
                      defaultValue={field.value}
                    >
                      <FormControl>
                        <SelectTrigger>
                          <SelectValue />
                        </SelectTrigger>
                      </FormControl>
                      <SelectContent>
                        <SelectItem value="import">Import New</SelectItem>
                        <SelectItem value="update">Update Existing</SelectItem>
                      </SelectContent>
                    </Select>
                  </FormItem>
                )}
              />

              <FormField
                control={form.control}
                name="entityType"
                render={({ field }) => (
                  <FormItem>
                    <FormLabel>Data Type</FormLabel>
                    <Select 
                      onValueChange={field.onChange} 
                      defaultValue={field.value}
                    >
                      <FormControl>
                        <SelectTrigger>
                          <SelectValue />
                        </SelectTrigger>
                      </FormControl>
                      <SelectContent>
                        <SelectItem value="products">Products</SelectItem>
                        <SelectItem value="inventory">Inventory</SelectItem>
                        <SelectItem value="pricing">Pricing</SelectItem>
                        <SelectItem value="customers">Customers</SelectItem>
                      </SelectContent>
                    </Select>
                  </FormItem>
                )}
              />
            </div>

            <div className="space-y-4">
              <FormField
                control={form.control}
                name="validateOnly"
                render={({ field }) => (
                  <FormItem className="flex items-center space-x-2">
                    <FormControl>
                      <Checkbox
                        checked={field.value}
                        onCheckedChange={field.onChange}
                      />
                    </FormControl>
                    <div className="space-y-1 leading-none">
                      <FormLabel>Validate Only</FormLabel>
                      <FormDescription>
                        Check for errors without making changes
                      </FormDescription>
                    </div>
                  </FormItem>
                )}
              />

              <FormField
                control={form.control}
                name="rollbackOnError"
                render={({ field }) => (
                  <FormItem className="flex items-center space-x-2">
                    <FormControl>
                      <Checkbox
                        checked={field.value}
                        onCheckedChange={field.onChange}
                        disabled={form.watch('validateOnly')}
                      />
                    </FormControl>
                    <div className="space-y-1 leading-none">
                      <FormLabel>Rollback on Error</FormLabel>
                      <FormDescription>
                        Undo all changes if any record fails
                      </FormDescription>
                    </div>
                  </FormItem>
                )}
              />
            </div>

            <Alert>
              <Info className="h-4 w-4" />
              <AlertDescription>
                <div className="flex items-center justify-between">
                  <span>Need a template? Download one for your data type</span>
                  <Button
                    type="button"
                    variant="ghost"
                    size="sm"
                    onClick={downloadTemplate}
                  >
                    <Download className="mr-2 h-4 w-4" />
                    Download Template
                  </Button>
                </div>
              </AlertDescription>
            </Alert>

            <FormField
              control={form.control}
              name="file"
              render={({ field: { onChange, value, ...field } }) => (
                <FormItem>
                  <FormLabel>CSV File</FormLabel>
                  <FormControl>
                    <FileUpload
                      {...field}
                      accept=".csv"
                      maxSize={50 * 1024 * 1024} // 50MB
                      onChange={(file) => onChange(file)}
                    />
                  </FormControl>
                  <FormDescription>
                    Maximum file size: 50MB. Large files will be processed in chunks.
                  </FormDescription>
                  <FormMessage />
                </FormItem>
              )}
            />

            <DialogFooter>
              <Button
                type="button"
                variant="outline"
                onClick={() => onOpenChange(false)}
                disabled={isUploading}
              >
                Cancel
              </Button>
              <Button type="submit" disabled={isUploading}>
                {isUploading ? 'Processing...' : 'Start Operation'}
              </Button>
            </DialogFooter>
          </form>
        </Form>
      </DialogContent>
    </Dialog>
  )
}
```

### Phase 6: Bulk Progress Tracker

```tsx
// components/features/bulk/bulk-progress-tracker.tsx
'use client'

import { useState, useEffect } from 'react'
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '@/components/ui/card'
import { Progress } from '@/components/ui/progress'
import { Badge } from '@/components/ui/badge'
import { Button } from '@/components/ui/button'
import { 
  RefreshCw, 
  CheckCircle, 
  XCircle, 
  AlertCircle,
  RotateCcw,
  Clock
} from 'lucide-react'
import { formatDistanceToNow } from 'date-fns'

interface BulkProgressTrackerProps {
  operationId: string
  onComplete?: () => void
  showRollbackButton?: boolean
}

interface ProgressData {
  operationId: string
  type?: string
  status: string
  totalRecords: number
  processedRecords: number
  successfulRecords: number
  failedRecords: number
  estimatedTimeRemaining?: number
  percentage?: number
  rollbackProgress?: {
    total: number
    processed: number
    successful: number
    failed: number
    percentage: number
  }
}

export function BulkProgressTracker({ 
  operationId, 
  onComplete,
  showRollbackButton = true 
}: BulkProgressTrackerProps) {
  const [progress, setProgress] = useState<ProgressData | null>(null)
  const [rollbackProgress, setRollbackProgress] = useState<ProgressData | null>(null)
  const [isRollingBack, setIsRollingBack] = useState(false)
  const [error, setError] = useState<string | null>(null)

  useEffect(() => {
    if (!operationId) return

    const eventSource = new EventSource(`/api/bulk/progress/${operationId}`)

    eventSource.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data)
        
        switch (data.type) {
          case 'initial':
          case 'progress':
            setProgress(data.progress)
            if (data.progress.status === 'completed' || 
                data.progress.status === 'failed' || 
                data.progress.status === 'cancelled') {
              onComplete?.()
            }
            break
            
          case 'rollback-progress':
            setRollbackProgress(data.progress)
            setIsRollingBack(true)
            if (data.progress.status === 'rolled_back') {
              setIsRollingBack(false)
              onComplete?.()
            }
            break
        }
      } catch (err) {
        console.error('Failed to parse SSE data:', err)
        setError('Failed to parse progress data')
      }
    }

    eventSource.onerror = (err) => {
      console.error('SSE error:', err)
      setError('Connection lost')
      eventSource.close()
    }

    return () => {
      eventSource.close()
    }
  }, [operationId, onComplete])

  const handleRollback = async () => {
    try {
      const response = await fetch('/api/bulk/rollback', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ operationId })
      })

      if (!response.ok) {
        throw new Error('Failed to start rollback')
      }

      setIsRollingBack(true)
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to start rollback')
    }
  }

  const getStatusIcon = (status: string) => {
    switch (status) {
      case 'completed':
        return <CheckCircle className="h-4 w-4 text-green-500" />
      case 'failed':
        return <XCircle className="h-4 w-4 text-red-500" />
      case 'processing':
        return <RefreshCw className="h-4 w-4 animate-spin text-blue-500" />
      case 'cancelled':
        return <XCircle className="h-4 w-4 text-gray-500" />
      case 'rolled_back':
        return <RotateCcw className="h-4 w-4 text-orange-500" />
      default:
        return <Clock className="h-4 w-4 text-gray-400" />
    }
  }

  const formatTimeRemaining = (seconds?: number) => {
    if (!seconds || seconds <= 0) return 'Calculating...'
    if (seconds < 60) return `${Math.ceil(seconds)}s remaining`
    if (seconds < 3600) return `${Math.ceil(seconds / 60)}m remaining`
    return `${Math.ceil(seconds / 3600)}h remaining`
  }

  if (error) {
    return (
      <Card className="border-red-200">
        <CardContent className="pt-6">
          <div className="flex items-center gap-2 text-red-600">
            <AlertCircle className="h-4 w-4" />
            <span>{error}</span>
          </div>
        </CardContent>
      </Card>
    )
  }

  const currentProgress = rollbackProgress || progress
  if (!currentProgress) {
    return (
      <Card>
        <CardContent className="pt-6">
          <div className="flex items-center gap-2">
            <RefreshCw className="h-4 w-4 animate-spin" />
            <span>Loading progress...</span>
          </div>
        </CardContent>
      </Card>
    )
  }

  const percentage = rollbackProgress?.percentage || 
    (currentProgress.totalRecords > 0 ? 
      (currentProgress.processedRecords / currentProgress.totalRecords) * 100 : 0)

  return (
    <Card className={rollbackProgress ? 'border-orange-200' : undefined}>
      <CardHeader className="pb-2">
        <div className="flex items-center justify-between">
          <div className="flex items-center gap-2">
            {getStatusIcon(currentProgress.status)}
            <CardTitle className="text-base">
              Operation {operationId.slice(0, 8)}...
            </CardTitle>
            <Badge variant={
              rollbackProgress ? 'destructive' :
              currentProgress.status === 'completed' ? 'success' :
              currentProgress.status === 'failed' ? 'destructive' :
              'default'
            }>
              {rollbackProgress ? 'Rolling Back' : currentProgress.status}
            </Badge>
          </div>
          
          {showRollbackButton && 
           progress?.status === 'completed' && 
           !isRollingBack && (
            <Button
              size="sm"
              variant="outline"
              onClick={handleRollback}
              className="text-orange-600 border-orange-200 hover:bg-orange-50"
            >
              <RotateCcw className="mr-2 h-4 w-4" />
              Rollback
            </Button>
          )}
        </div>
        
        {rollbackProgress && (
          <CardDescription>
            Rolling back changes from completed operation
          </CardDescription>
        )}
      </CardHeader>
      
      <CardContent className="space-y-4">
        <div className="space-y-2">
          <div className="flex justify-between text-sm">
            <span>Progress</span>
            <span>{Math.round(percentage)}%</span>
          </div>
          <Progress value={percentage} className="h-2" />
          <div className="flex justify-between text-xs text-muted-foreground">
            <span>
              {currentProgress.processedRecords.toLocaleString()} / {' '}
              {currentProgress.totalRecords.toLocaleString()} records
            </span>
            {currentProgress.estimatedTimeRemaining && (
              <span>{formatTimeRemaining(currentProgress.estimatedTimeRemaining)}</span>
            )}
          </div>
        </div>

        <div className="grid grid-cols-2 gap-4 text-sm">
          <div className="space-y-1">
            <div className="text-green-600">
               {currentProgress.successfulRecords.toLocaleString()} successful
            </div>
            {currentProgress.failedRecords > 0 && (
              <div className="text-red-600">
                 {currentProgress.failedRecords.toLocaleString()} failed
              </div>
            )}
          </div>
          
          {currentProgress.status === 'processing' && (
            <div className="text-xs text-muted-foreground">
              Processing in batches for optimal performance
            </div>
          )}
        </div>
      </CardContent>
    </Card>
  )
}
```

### Phase 7: Server Action

```typescript
// app/actions/bulk-operations.ts
'use server'

import { createServerClient } from '@/lib/supabase/server'
import { BulkOperationsEngine } from '@/lib/bulk/bulk-operations-engine'
import { validateCSVFile } from '@/lib/csv/parser'
import { revalidatePath } from 'next/cache'

export async function startBulkOperation(formData: FormData) {
  const supabase = createServerClient()
  
  // Get user
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) throw new Error('Unauthorized')

  // Get form data
  const file = formData.get('file') as File
  const operationType = formData.get('operationType') as string
  const entityType = formData.get('entityType') as string
  const validateOnly = formData.get('validateOnly') === 'true'
  const rollbackOnError = formData.get('rollbackOnError') === 'true'

  // Validate file
  const validation = validateCSVFile(file)
  if (!validation.valid) {
    throw new Error(validation.error)
  }

  // Create engine and start operation
  const engine = new BulkOperationsEngine()
  const operationId = await engine.startOperation(
    file,
    {
      operationType: operationType as any,
      entityType: entityType as any,
      validateOnly,
      rollbackOnError,
      chunkSize: 500,
      maxConcurrent: 3
    },
    user.id
  )

  // Revalidate pages
  revalidatePath('/bulk-operations')
  
  return { operationId }
}

export async function cancelBulkOperation(operationId: string) {
  const supabase = createServerClient()
  
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) throw new Error('Unauthorized')

  const engine = new BulkOperationsEngine()
  await engine.cancelOperation(operationId, user.id)

  revalidatePath('/bulk-operations')
}

export async function rollbackBulkOperation(operationId: string) {
  const supabase = createServerClient()
  
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) throw new Error('Unauthorized')

  const engine = new BulkOperationsEngine()
  
  // Start rollback asynchronously - don't await to return immediately
  engine.rollbackOperation(operationId).catch(err => {
    console.error(`Rollback operation ${operationId} failed:`, err)
  })

  revalidatePath('/bulk-operations')
  return { success: true }
}
```

### Phase 8: Rollback API Routes

```typescript
// app/api/bulk/rollback/route.ts
import { createServerClient } from '@/lib/supabase/server'
import { BulkOperationsEngine } from '@/lib/bulk/bulk-operations-engine'
import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  try {
    const supabase = createServerClient()
    
    // Verify user has access
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const { operationId } = await request.json()
    
    if (!operationId) {
      return NextResponse.json({ error: 'Operation ID required' }, { status: 400 })
    }

    // Verify operation belongs to user's organization
    const { data: operation } = await supabase
      .from('bulk_operations')
      .select('*')
      .eq('id', operationId)
      .single()

    if (!operation) {
      return NextResponse.json({ error: 'Operation not found' }, { status: 404 })
    }

    // Check if operation can be rolled back
    if (operation.status !== 'completed') {
      return NextResponse.json(
        { error: 'Only completed operations can be rolled back' }, 
        { status: 400 }
      )
    }

    // Start rollback process
    const engine = new BulkOperationsEngine()
    
    // Start rollback asynchronously
    engine.rollbackOperation(operationId).catch(err => {
      console.error(`Rollback operation ${operationId} failed:`, err)
    })

    return NextResponse.json({ 
      success: true, 
      message: 'Rollback initiated',
      operationId 
    })

  } catch (error) {
    console.error('Rollback API error:', error)
    return NextResponse.json(
      { error: 'Internal server error' }, 
      { status: 500 }
    )
  }
}

// app/api/bulk/cancel/route.ts
import { createServerClient } from '@/lib/supabase/server'
import { BulkOperationsEngine } from '@/lib/bulk/bulk-operations-engine'
import { NextRequest, NextResponse } from 'next/server'

export async function POST(request: NextRequest) {
  try {
    const supabase = createServerClient()
    
    const { data: { user } } = await supabase.auth.getUser()
    if (!user) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const { operationId } = await request.json()
    
    if (!operationId) {
      return NextResponse.json({ error: 'Operation ID required' }, { status: 400 })
    }

    const engine = new BulkOperationsEngine()
    await engine.cancelOperation(operationId, user.id)

    return NextResponse.json({ success: true })

  } catch (error) {
    console.error('Cancel API error:', error)
    return NextResponse.json(
      { error: 'Internal server error' }, 
      { status: 500 }
    )
  }
}
```

## Implementation Validation

### Gate 1: Stream Processing 
- [ ] Handles 1M+ record CSV files without memory issues
- [ ] Processes chunks concurrently with configurable limits
- [ ] Provides accurate progress tracking via SSE
- [ ] Gracefully handles connection interruptions

### Gate 2: Error Handling 
- [ ] Validates each record against schema
- [ ] Collects and reports all errors with context
- [ ] Supports partial success with detailed reporting
- [ ] Implements configurable rollback on error

### Gate 3: Performance 
- [ ] Processes 10,000 records/minute minimum
- [ ] Maintains UI responsiveness during operations
- [ ] Efficient database batch operations
- [ ] Proper connection pooling and cleanup

### Gate 4: Security 
- [ ] Validates file types and sizes
- [ ] Prevents formula injection attacks
- [ ] Enforces RLS on all operations
- [ ] Sanitizes all user input

### Gate 5: User Experience 
- [ ] Real-time progress with time estimates
- [ ] Clear error messages with row numbers
- [ ] Download templates for each entity type
- [ ] Operation history with filtering

## Key Decisions

1. **Streaming Architecture**: Node.js streams for memory efficiency
2. **Chunk Processing**: Configurable batch sizes for optimal performance
3. **SSE for Progress**: Real-time updates without WebSocket complexity
4. **Rollback System**: Transaction-like behavior for data integrity
5. **Validation First**: Separate validation pass before processing

## Out of Scope (Future PRPs)
- Scheduled bulk operations
- Multi-file imports
- Custom field mapping UI
- Export scheduling
- Bulk operation templates

This completes PRP-017 for Bulk Operations.